{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "\n",
    "Pytorch is a widely adopted deep learning library that has the following unique feature:\n",
    "<br>\n",
    "It operates on a **dynamic** computational graph. \n",
    "\n",
    "The dynamic frameworks allows to write regular Python code, and use regular python debugging, to develop our neural network logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Tensors\n",
    "\n",
    "Tensors are fundamental operational building blocks in deep learning. They are multi-dimensional matrices.\n",
    "\n",
    "#### Types of Tensors\n",
    "- 8-bit (Signed + Unsigned)\n",
    "- 16-bit (Float + Int)\n",
    "- 32-bit (Float + Int)\n",
    "- 64-bit (Float + Int)\n",
    "\n",
    "Let us create some basic Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor\n",
    "new_tensor = torch.Tensor([[1, 2], [3, 4]])\n",
    "print(new_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An **empty tensor**, will be filled with random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00, -2.5244e-29,  8.0030e-15],\n",
      "        [ 4.6577e-10,  7.9936e-15, -4.6577e-10]])\n"
     ]
    }
   ],
   "source": [
    "# create a 2 x 3 tensor with random values\n",
    "empty_tensor = torch.Tensor(2, 3)\n",
    "print(empty_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a tensor whose values are within a **specific range** we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8610, -0.9857, -0.3219],\n",
      "        [-0.6543,  0.9118,  0.4297]])\n",
      "tensor([[0.6444, 0.7462, 0.2848],\n",
      "        [0.8070, 0.7104, 0.9435]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# create a 2 x 3 tensor with random values between -1and 1\n",
    "uniform_tensor = torch.Tensor(2, 3).uniform_(-1, 1)\n",
    "print(uniform_tensor)\n",
    "\n",
    "# create a 2 x 3 tensor with random values from a uniform distribution on the interval [0, 1)\n",
    "rand_tensor = torch.rand(2, 3)\n",
    "print(rand_tensor)\n",
    "\n",
    "# create a 2 x 3 tensor of zeros\n",
    "zero_tensor = torch.zeros(2, 3)\n",
    "print(zero_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing and Indexing\n",
    "\n",
    "To access or replace elements in a tensor, we can use indexing. \n",
    "For example, `new_tensor[0][0]` will return a tensor object that contains the element at position 0, 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100.,   2.],\n",
      "        [  3.,   4.]])\n"
     ]
    }
   ],
   "source": [
    "# replace an element at position 0, 0\n",
    "new_tensor[0][0] = 100\n",
    "print(new_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scalar object can be also accessed via `.item()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# access an element at position 1, 0\n",
    "print(new_tensor[1][0])           # tensor([ 3.])\n",
    "print(new_tensor[1][0].item())    # 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing can also be used to access every row and column in a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 4., 7.])\n",
      "tensor([3., 6., 9.])\n",
      "tensor([7., 8., 9.])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "## slicing examples\n",
    "slice_tensor = torch.Tensor([[1, 2, 3], \n",
    "                             [4, 5, 6], \n",
    "                             [7, 8, 9]])\n",
    "\n",
    "# elements from every row, first column\n",
    "print(slice_tensor[:, 0])         # tensor([ 1.,  4.,  7.])\n",
    "\n",
    "# elements from every row, last column\n",
    "print(slice_tensor[:, -1])        # tensor([ 3.,  6.,  9.])\n",
    "\n",
    "# all elements on the second row\n",
    "print(slice_tensor[2, :])         # tensor([ 4.,  5.,  6.])\n",
    "\n",
    "# all elements from first two rows\n",
    "print(slice_tensor[:2, :])        # tensor([[ 1.,  2.,  3.],\n",
    "                                  #         [ 4.,  5.,  6.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Information\n",
    "In order to check the type of a tensor, .type() is used. For the shape of a tensor, either .shape or .size() can be used. .dim() is for accessing the dimension of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# type of a tensor\n",
    "print(new_tensor.type())   # 'torch.FloatTensor'\n",
    "\n",
    "# shape of a tensor\n",
    "print(new_tensor.shape)    # torch.Size([2, 2])\n",
    "print(new_tensor.size())   # torch.Size([2, 2])\n",
    "\n",
    "# dimension of a tensor\n",
    "print(new_tensor.dim())    # 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reshape a tensor, simply use the code .view(n,m). This will convert the shape of a tensor to the size n x m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4.]])\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.]])\n"
     ]
    }
   ],
   "source": [
    "reshape_tensor = torch.Tensor([[1, 2], [3, 4]])\n",
    "\n",
    "print(reshape_tensor.view(1,4))   # tensor([[ 1.,  2.,  3.,  4.]])\n",
    "\n",
    "print(reshape_tensor.view(4,1))   # tensor([[ 1.],[ 2.],[ 3.],[ 4.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Bridge\n",
    "\n",
    "We can convert a torch Tensor to a numpy array and vice versa easily.\n",
    "\n",
    "The torch Tensor and numpy array will share their underlying memory locations, and changing one will change the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5)\n",
    "y = x.numpy()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Tensor Operations\n",
    "\n",
    "#### Transpose: `.t()` or `.permute(-1, 0)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n",
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3], [4,5,6]])\n",
    "print(x)\n",
    "\n",
    "# regular transpose function\n",
    "print(x.t())\n",
    "\n",
    "# transpose via permute function\n",
    "print(x.permute(-1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Product  `a.cross(b)` or `torch.cross(a, b)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1739, -0.7375, -0.9774],\n",
      "        [ 0.0965, -0.4080,  0.2240],\n",
      "        [ 0.5896,  1.2675,  0.1583]])\n"
     ]
    }
   ],
   "source": [
    "tensor_1 = torch.randn(3, 3)\n",
    "tensor_2 = torch.randn(3, 3)\n",
    "\n",
    "cross_prod = tensor_1.cross(tensor_2)\n",
    "print(cross_prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Product: `.mm()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1121, -3.6505,  1.2682],\n",
      "        [ 0.4588,  1.9647,  0.1891],\n",
      "        [ 0.3276, -0.1029,  0.8782]])\n"
     ]
    }
   ],
   "source": [
    "maxtrix_prod = tensor_1.mm(tensor_2)\n",
    "print(maxtrix_prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elementwise Multiplication: `.mul()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3745, -1.2369, -0.0029],\n",
      "        [-0.3203, -0.1416, -0.5198],\n",
      "        [ 0.0028, -0.7180,  0.3890]])\n"
     ]
    }
   ],
   "source": [
    "element_mult = tensor_1.mul(tensor_2)\n",
    "print(element_mult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00, -5.0487e-29,  8.3316e-15],\n",
      "        [ 3.6902e+19,  4.8250e+01,  3.9420e+12]])\n"
     ]
    }
   ],
   "source": [
    "x, y = torch.Tensor(2,3), torch.Tensor(2,3)\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "z = x + y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Autograd\n",
    "\n",
    "The autograd package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different.\n",
    "\n",
    "## Variable\n",
    "\n",
    "`autograd.Variable` is the central class of the package. \n",
    "It wraps a Tensor, and supports nearly all of operations defined on it. \n",
    "Once you finish your computation you can call `.backward()` and have all the gradients computed automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.],\n",
      "        [-1.],\n",
      "        [ 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "y = Variable(torch.Tensor([[1.0], [-1.0], [1.0]]),  requires_grad=True)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6667, grad_fn=<L1LossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.L1Loss()\n",
    "target = torch.Tensor([[1.0], [1.0], [1.0]])\n",
    "output = loss(y, target)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<L1LossBackward object at 0x11ee52a90>\n"
     ]
    }
   ],
   "source": [
    "print(output.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- Gradients accumulate everytime you call them, by default, be sure to call `zero.gradient()` to avoid that\n",
    "\n",
    "- PyTorch supports various Tensor types. Be sure to check for the types to avoid Type compatibility errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
